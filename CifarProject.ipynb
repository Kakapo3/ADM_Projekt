{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analiza danych multimedialnych projekt\n",
    "\n",
    "### Autorzy: Kamil Sakowicz, Kacper Majkowski\n",
    "\n",
    "\n",
    "\n",
    "## Opis projektu\n",
    "\n",
    "Celem projektu było stworzenie modelu, który będzie umieć rozpoznawać przedmioty na obrazach.\n",
    "\n",
    "Do szkolenia modelu został wykorzystany zbiór danych CIFAR-10. Zbiór ten zawiera 60000 kolorowych obrazów o wymiarach 32x32, zbiór treningowy zawiera 50000 obrazów, a zbiór testowy 10000. W zbiorze tym wydzielonych jest 10 rozłącznych grup przedmiotów, takich jak: samolot, samochód, ptak, kot, jeleń, pies, żaba, koń, statek, ciężarówka. Każda klasa zawiera 6000 zdjęć, a na każdym zdjęciu znajduje się tylko jeden przedmiot reprezentujący tę klasę.\n",
    "\n",
    "Model zaimplementowaliśmy przy zastosowaniu konwolucyjnych sieci neuronowych, które są bardzo skuteczne w rozpoznawaniu obrazów.\n",
    "\n",
    "Jako ostatni etap projektu, chcieliśmy sprawdzić skuteczność tego modelu na innych zbiorach obrazów, aby ocenić jego faktyczną skuteczność i przydatność\n"
   ],
   "id": "2fd7d13f11455c44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Wczytanie bibliotek",
   "id": "dc1af58e1b9faa41"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-18T15:54:16.054883Z",
     "start_time": "2025-01-18T15:54:03.690186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.src.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.src.layers import Conv2D, BatchNormalization, Dense, Flatten, MaxPooling2D, Dropout\n",
    "from keras.src.optimizers import Adam\n",
    "from keras.src.regularizers import L2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import  tensorflow as tf"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:29:39.926713Z",
     "start_time": "2025-01-17T19:29:39.918103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_picture(picture):\n",
    "    plt.imshow(picture)\n",
    "    plt.show()\n",
    "\n",
    "def convert_to_hot_one(y_tr, y_valid, y_tst):\n",
    "    y_tr = tf.keras.utils.to_categorical(y_tr, 10)\n",
    "    y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "    y_tst = tf.keras.utils.to_categorical(y_tst, 10)\n",
    "    return y_tr, y_valid, y_tst"
   ],
   "id": "1cf576c62cfa55e2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Wczytanie danych ze zbioru",
   "id": "82f2d309a0fbdba6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T19:29:43.581785Z",
     "start_time": "2025-01-17T19:29:41.736412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(x_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
   ],
   "id": "ff5f7b34bab35d5f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sprawdzenie wymiarów danych",
   "id": "4dff07556aa3ac76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T20:22:48.744452400Z",
     "start_time": "2025-01-02T20:22:48.729809900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Train images: ', X_train.shape)\n",
    "print('Train labels: ', y_train.shape)\n",
    "\n",
    "print('Validation images: ', X_valid.shape)\n",
    "print('Validation labels: ', y_valid.shape)\n",
    "\n",
    "print('Test images: ', X_test.shape)\n",
    "print('Test labels: ', y_test.shape)"
   ],
   "id": "a09d6c8df31d5cfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images:  (45000, 32, 32, 3)\n",
      "Train labels:  (45000, 1)\n",
      "Validation images:  (5000, 32, 32, 3)\n",
      "Validation labels:  (5000, 1)\n",
      "Test images:  (10000, 32, 32, 3)\n",
      "Test labels:  (10000, 1)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Standaryzacja danych oraz przekształcenie etykiet za pomocą hot-one\n",
    "\n",
    "Ustawiamy typ wartości na float, następnie normalizujemy wartości, aby były one w tej samej skali. Sieci neurowe są wrażliwe na skale danych wejściowych, więc dzięki normalizacji temu model będzie się lepiej uczył."
   ],
   "id": "924510dcb95e2727"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T20:22:50.090851500Z",
     "start_time": "2025-01-02T20:22:48.733450500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test  = X_test.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "\n",
    "mean = np.mean(X_train)\n",
    "std  = np.std(X_train)\n",
    "\n",
    "X_train = (X_train-mean)/(std+1e-7)\n",
    "X_test  = (X_test-mean) /(std+1e-7)\n",
    "X_valid = (X_valid-mean)/(std+1e-7)\n",
    "\n",
    "y_train, y_valid, y_tst = convert_to_hot_one(y_train, y_valid, y_test)"
   ],
   "id": "1d9584cb8efe372f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Tworzenie modelu\n",
    "\n",
    "Model został zrobiony w następujący sposób: 2 warstwy konwolucyjne, po każdej z nich warstwa normalizująca, następnie warstwa MaxPooling oraz Dropout, aby zmniejszyć ilość aktywnych neuronów.\n",
    "\n",
    "Schemat ten powtarza się 2 razy, w drugim powtórzeniu zwiększamy ilość filtrów warstw konwolucyjnych dwukrotnie, oraz zwiększamy dropout rate o 0.1.\n",
    "\n",
    "Po drugim powtórzeniu stosujemy warstwę flatten oraz dense, aby uzyskać wyniki w postaci wektora odpowiadającemu prawdopodobieństwa przynależności do jednej z 10 klas."
   ],
   "id": "741b2c7f0ae8b6b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T20:22:50.227124800Z",
     "start_time": "2025-01-02T20:22:50.093852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential()\n",
    "weight_decay = 0.0001\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=L2(weight_decay), input_shape=X_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=L2(weight_decay), input_shape=X_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=L2(weight_decay), input_shape=X_train.shape[1:]))   \n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=L2(weight_decay), input_shape=X_train.shape[1:]))   \n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))"
   ],
   "id": "63a250025793b90b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamil\\PycharmProjects\\ADM_Projekt\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T20:22:50.248234300Z",
     "start_time": "2025-01-02T20:22:50.220122900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "id": "3054c89ccc13373e",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m896\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m128\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │         \u001B[38;5;34m9,248\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m128\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001B[38;5;33mMaxPooling2D\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │        \u001B[38;5;34m18,496\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │           \u001B[38;5;34m256\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │        \u001B[38;5;34m36,928\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │           \u001B[38;5;34m256\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m64\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m64\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4096\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │        \u001B[38;5;34m40,970\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,970</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m107,306\u001B[0m (419.16 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,306</span> (419.16 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m106,922\u001B[0m (417.66 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,922</span> (417.66 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m384\u001B[0m (1.50 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Trenowanie modelu\n",
    "\n",
    "Jako optymalizator został wykorzystany Adam, jako funkcje straty użyliśmy entropii krzyżowej dla wielu klas.\n",
    "\n",
    "Ponadto, do trenowania tego modelu dodaliśmy funkcje ReduceLROnPlateau do zwiększenia dokładności modelu, oraz funkcję EarlyStopping, która zatrzyma uczenie, jeśli model nie poprawia się przez określony czas."
   ],
   "id": "532ed563f93ca807"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-01-02T21:04:12.135629400Z",
     "start_time": "2025-01-02T20:22:50.236231500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=[reduce_lr, early_stopping], \n",
    "          verbose=2)"
   ],
   "id": "df0fc1fa52e53669",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "704/704 - 36s - 51ms/step - accuracy: 0.3373 - loss: 2.2705 - val_accuracy: 0.4704 - val_loss: 1.5328 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "704/704 - 34s - 48ms/step - accuracy: 0.4529 - loss: 1.6769 - val_accuracy: 0.5364 - val_loss: 1.3215 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "704/704 - 34s - 49ms/step - accuracy: 0.5083 - loss: 1.4652 - val_accuracy: 0.5640 - val_loss: 1.2359 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "704/704 - 34s - 49ms/step - accuracy: 0.5513 - loss: 1.3315 - val_accuracy: 0.5986 - val_loss: 1.1452 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "704/704 - 34s - 49ms/step - accuracy: 0.5868 - loss: 1.2234 - val_accuracy: 0.6294 - val_loss: 1.0710 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "704/704 - 35s - 50ms/step - accuracy: 0.6122 - loss: 1.1379 - val_accuracy: 0.6448 - val_loss: 1.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "704/704 - 35s - 50ms/step - accuracy: 0.6403 - loss: 1.0576 - val_accuracy: 0.6604 - val_loss: 0.9841 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "704/704 - 35s - 49ms/step - accuracy: 0.6566 - loss: 1.0081 - val_accuracy: 0.6782 - val_loss: 0.9299 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "704/704 - 35s - 50ms/step - accuracy: 0.6769 - loss: 0.9508 - val_accuracy: 0.6832 - val_loss: 0.9151 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "704/704 - 35s - 50ms/step - accuracy: 0.6863 - loss: 0.9156 - val_accuracy: 0.6882 - val_loss: 0.8956 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "704/704 - 35s - 50ms/step - accuracy: 0.6996 - loss: 0.8806 - val_accuracy: 0.6948 - val_loss: 0.8767 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "704/704 - 35s - 50ms/step - accuracy: 0.7117 - loss: 0.8386 - val_accuracy: 0.7052 - val_loss: 0.8464 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "704/704 - 36s - 51ms/step - accuracy: 0.7217 - loss: 0.8146 - val_accuracy: 0.7058 - val_loss: 0.8432 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "704/704 - 36s - 51ms/step - accuracy: 0.7319 - loss: 0.7835 - val_accuracy: 0.7160 - val_loss: 0.8277 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "704/704 - 36s - 51ms/step - accuracy: 0.7385 - loss: 0.7648 - val_accuracy: 0.7250 - val_loss: 0.7960 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "704/704 - 35s - 50ms/step - accuracy: 0.7469 - loss: 0.7411 - val_accuracy: 0.7362 - val_loss: 0.7742 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "704/704 - 34s - 48ms/step - accuracy: 0.7512 - loss: 0.7234 - val_accuracy: 0.7256 - val_loss: 0.8003 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "704/704 - 35s - 50ms/step - accuracy: 0.7578 - loss: 0.7079 - val_accuracy: 0.7306 - val_loss: 0.7775 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "704/704 - 34s - 49ms/step - accuracy: 0.7625 - loss: 0.6867 - val_accuracy: 0.7454 - val_loss: 0.7629 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "704/704 - 33s - 47ms/step - accuracy: 0.7672 - loss: 0.6728 - val_accuracy: 0.7386 - val_loss: 0.7534 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "704/704 - 35s - 49ms/step - accuracy: 0.7740 - loss: 0.6562 - val_accuracy: 0.7518 - val_loss: 0.7344 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "704/704 - 34s - 49ms/step - accuracy: 0.7821 - loss: 0.6373 - val_accuracy: 0.7536 - val_loss: 0.7341 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "704/704 - 33s - 47ms/step - accuracy: 0.7854 - loss: 0.6255 - val_accuracy: 0.7514 - val_loss: 0.7355 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "704/704 - 35s - 50ms/step - accuracy: 0.7906 - loss: 0.6133 - val_accuracy: 0.7518 - val_loss: 0.7280 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "704/704 - 35s - 50ms/step - accuracy: 0.7949 - loss: 0.5993 - val_accuracy: 0.7572 - val_loss: 0.7302 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.7958 - loss: 0.5895 - val_accuracy: 0.7532 - val_loss: 0.7297 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "704/704 - 34s - 48ms/step - accuracy: 0.7974 - loss: 0.5815 - val_accuracy: 0.7550 - val_loss: 0.7161 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "704/704 - 34s - 49ms/step - accuracy: 0.8047 - loss: 0.5621 - val_accuracy: 0.7626 - val_loss: 0.7073 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "704/704 - 34s - 48ms/step - accuracy: 0.8089 - loss: 0.5549 - val_accuracy: 0.7630 - val_loss: 0.7077 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "704/704 - 31s - 44ms/step - accuracy: 0.8125 - loss: 0.5404 - val_accuracy: 0.7626 - val_loss: 0.7150 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "704/704 - 31s - 43ms/step - accuracy: 0.8153 - loss: 0.5340 - val_accuracy: 0.7672 - val_loss: 0.6997 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "704/704 - 31s - 44ms/step - accuracy: 0.8210 - loss: 0.5230 - val_accuracy: 0.7724 - val_loss: 0.6989 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "704/704 - 31s - 43ms/step - accuracy: 0.8247 - loss: 0.5093 - val_accuracy: 0.7684 - val_loss: 0.7110 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "704/704 - 31s - 43ms/step - accuracy: 0.8272 - loss: 0.5022 - val_accuracy: 0.7658 - val_loss: 0.6946 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8298 - loss: 0.4969 - val_accuracy: 0.7678 - val_loss: 0.6964 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8333 - loss: 0.4849 - val_accuracy: 0.7702 - val_loss: 0.6928 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "704/704 - 31s - 44ms/step - accuracy: 0.8347 - loss: 0.4798 - val_accuracy: 0.7712 - val_loss: 0.6871 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "704/704 - 31s - 43ms/step - accuracy: 0.8371 - loss: 0.4745 - val_accuracy: 0.7756 - val_loss: 0.6940 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8396 - loss: 0.4650 - val_accuracy: 0.7746 - val_loss: 0.6965 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8428 - loss: 0.4585 - val_accuracy: 0.7696 - val_loss: 0.7024 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8456 - loss: 0.4503 - val_accuracy: 0.7744 - val_loss: 0.6800 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8469 - loss: 0.4431 - val_accuracy: 0.7756 - val_loss: 0.6800 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "704/704 - 34s - 48ms/step - accuracy: 0.8523 - loss: 0.4339 - val_accuracy: 0.7702 - val_loss: 0.6992 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "704/704 - 31s - 44ms/step - accuracy: 0.8511 - loss: 0.4305 - val_accuracy: 0.7792 - val_loss: 0.7041 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "704/704 - 34s - 49ms/step - accuracy: 0.8522 - loss: 0.4285 - val_accuracy: 0.7754 - val_loss: 0.7016 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8546 - loss: 0.4186 - val_accuracy: 0.7852 - val_loss: 0.6869 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8553 - loss: 0.4148 - val_accuracy: 0.7842 - val_loss: 0.6942 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "704/704 - 31s - 45ms/step - accuracy: 0.8608 - loss: 0.4033 - val_accuracy: 0.7860 - val_loss: 0.6836 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8593 - loss: 0.4034 - val_accuracy: 0.7868 - val_loss: 0.6811 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8636 - loss: 0.3976 - val_accuracy: 0.7844 - val_loss: 0.6908 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "704/704 - 31s - 45ms/step - accuracy: 0.8659 - loss: 0.3924 - val_accuracy: 0.7798 - val_loss: 0.6997 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "704/704 - 31s - 44ms/step - accuracy: 0.8731 - loss: 0.3695 - val_accuracy: 0.7858 - val_loss: 0.6793 - learning_rate: 5.0000e-05\n",
      "Epoch 53/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8778 - loss: 0.3562 - val_accuracy: 0.7838 - val_loss: 0.6775 - learning_rate: 5.0000e-05\n",
      "Epoch 54/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8774 - loss: 0.3555 - val_accuracy: 0.7878 - val_loss: 0.6742 - learning_rate: 5.0000e-05\n",
      "Epoch 55/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8765 - loss: 0.3582 - val_accuracy: 0.7876 - val_loss: 0.6763 - learning_rate: 5.0000e-05\n",
      "Epoch 56/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8799 - loss: 0.3504 - val_accuracy: 0.7952 - val_loss: 0.6718 - learning_rate: 5.0000e-05\n",
      "Epoch 57/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8810 - loss: 0.3464 - val_accuracy: 0.7880 - val_loss: 0.6837 - learning_rate: 5.0000e-05\n",
      "Epoch 58/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8825 - loss: 0.3433 - val_accuracy: 0.7846 - val_loss: 0.6752 - learning_rate: 5.0000e-05\n",
      "Epoch 59/100\n",
      "704/704 - 30s - 43ms/step - accuracy: 0.8812 - loss: 0.3449 - val_accuracy: 0.7888 - val_loss: 0.6750 - learning_rate: 5.0000e-05\n",
      "Epoch 60/100\n",
      "704/704 - 31s - 44ms/step - accuracy: 0.8843 - loss: 0.3372 - val_accuracy: 0.7860 - val_loss: 0.6849 - learning_rate: 5.0000e-05\n",
      "Epoch 61/100\n",
      "704/704 - 31s - 45ms/step - accuracy: 0.8860 - loss: 0.3357 - val_accuracy: 0.7904 - val_loss: 0.6730 - learning_rate: 5.0000e-05\n",
      "Epoch 62/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8853 - loss: 0.3350 - val_accuracy: 0.7894 - val_loss: 0.6838 - learning_rate: 5.0000e-05\n",
      "Epoch 63/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8861 - loss: 0.3319 - val_accuracy: 0.7918 - val_loss: 0.6792 - learning_rate: 5.0000e-05\n",
      "Epoch 64/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8859 - loss: 0.3291 - val_accuracy: 0.7888 - val_loss: 0.6870 - learning_rate: 5.0000e-05\n",
      "Epoch 65/100\n",
      "704/704 - 31s - 44ms/step - accuracy: 0.8881 - loss: 0.3241 - val_accuracy: 0.7878 - val_loss: 0.6918 - learning_rate: 5.0000e-05\n",
      "Epoch 66/100\n",
      "704/704 - 32s - 46ms/step - accuracy: 0.8886 - loss: 0.3206 - val_accuracy: 0.7894 - val_loss: 0.6872 - learning_rate: 5.0000e-05\n",
      "Epoch 67/100\n",
      "704/704 - 34s - 48ms/step - accuracy: 0.8910 - loss: 0.3187 - val_accuracy: 0.7934 - val_loss: 0.6795 - learning_rate: 2.5000e-05\n",
      "Epoch 68/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8935 - loss: 0.3084 - val_accuracy: 0.7948 - val_loss: 0.6776 - learning_rate: 2.5000e-05\n",
      "Epoch 69/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8952 - loss: 0.3067 - val_accuracy: 0.7914 - val_loss: 0.6786 - learning_rate: 2.5000e-05\n",
      "Epoch 70/100\n",
      "704/704 - 37s - 52ms/step - accuracy: 0.8930 - loss: 0.3092 - val_accuracy: 0.7964 - val_loss: 0.6742 - learning_rate: 2.5000e-05\n",
      "Epoch 71/100\n",
      "704/704 - 33s - 47ms/step - accuracy: 0.8956 - loss: 0.3044 - val_accuracy: 0.7956 - val_loss: 0.6766 - learning_rate: 2.5000e-05\n",
      "Epoch 72/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8963 - loss: 0.3061 - val_accuracy: 0.7958 - val_loss: 0.6762 - learning_rate: 2.5000e-05\n",
      "Epoch 73/100\n",
      "704/704 - 31s - 45ms/step - accuracy: 0.8972 - loss: 0.3005 - val_accuracy: 0.7956 - val_loss: 0.6738 - learning_rate: 2.5000e-05\n",
      "Epoch 74/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8976 - loss: 0.3001 - val_accuracy: 0.7916 - val_loss: 0.6816 - learning_rate: 2.5000e-05\n",
      "Epoch 75/100\n",
      "704/704 - 31s - 45ms/step - accuracy: 0.8986 - loss: 0.2975 - val_accuracy: 0.7926 - val_loss: 0.6780 - learning_rate: 2.5000e-05\n",
      "Epoch 76/100\n",
      "704/704 - 32s - 45ms/step - accuracy: 0.8965 - loss: 0.3019 - val_accuracy: 0.7894 - val_loss: 0.6814 - learning_rate: 2.5000e-05\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x1c258ddf560>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Testowanie modelu\n",
    "\n",
    "Model dla danych testowych osiągnął dokładność 0.789, co jest całkiem dobrym wynikiem. Można ten model poprawić poprzez dodanie kolejnych warstw, jednak uznaliśmy, że na potrzeby tego projektu wynik jest zadowalający."
   ],
   "id": "9330de9ea662cca1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T21:45:10.865829Z",
     "start_time": "2025-01-03T21:45:05.888949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = tf.keras.models.load_model('first_model.keras')\n",
    "test_loss, test_acc = model.evaluate(X_test, y_tst, verbose=1)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)\n",
    "print('Test Loss:    ', test_loss)"
   ],
   "id": "46250dd1d7a9044e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kacper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 20 variables whereas the saved optimizer has 38 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 13ms/step - accuracy: 0.7937 - loss: 0.6785\n",
      "\n",
      "Test Accuracy: 0.7896000146865845\n",
      "Test Loss:     0.6862348914146423\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model.save('first_model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-02T21:24:16.515656700Z",
     "start_time": "2025-01-02T21:24:16.470246900Z"
    }
   },
   "id": "c1b27a271a26f37c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sprawdzenie modelu dla innych zbiorów danych",
   "id": "a6ad3efe15bf8ec1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T15:56:43.749595Z",
     "start_time": "2025-01-18T15:56:43.569496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.load_model('first_model.keras')\n",
    "\n",
    "def test_accuracy_on_dataset(directory, target_result_index):\n",
    "    X = np.ndarray(shape=(0, 32, 32, 3), dtype=np.float32)\n",
    "\n",
    "    for foldername in os.listdir(directory):\n",
    "        directory2 = os.path.join(directory, foldername)\n",
    "        for filename in os.listdir(directory2):\n",
    "            if filename.endswith('.jpg'):\n",
    "                f = os.path.join(directory2, filename)\n",
    "                img = cv2.imread(f)\n",
    "                img = cv2.resize(img, (32, 32))\n",
    "                X = np.append(X, [img], axis=0)\n",
    "        results = model.predict(X)\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for r in results:\n",
    "            arg = np.argmax(r)\n",
    "            if arg == target_result_index:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "        print(foldername + ' accuracy:', correct / total)"
   ],
   "id": "ed7ca48b576d2059",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Wyniki i wnioski\n",
    "\n",
    "Wyniki modelu dla innych zbiorów danych są słabe. Może to być spowodowane specyfiką nowych danych, na których np. może się znajdować parę obiektów danej klasy, na co model nie jest przygotowany. Mogą się również w nich znajdować obiekty innych klas lub obiekty, które nie są przypisane do żadnej klasy, co również może powodować słabe działanie tego modelu"
   ],
   "id": "64c05157f5adcb2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T16:22:33.230510Z",
     "start_time": "2025-01-18T16:22:30.821375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_accuracy_on_dataset('Cars Dataset/test', 1) # Średnia dokładność ~35%\n",
    "test_accuracy_on_dataset('dogs/data/test', 5) # ~9%\n",
    "test_accuracy_on_dataset('cats', 3) # ~12%"
   ],
   "id": "a292fd22a4de271b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m17/17\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "animal animal_faces dog dog_face accuracy: 0.08506616257088846\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step\n",
      "animal dog accuracy: 0.08415841584158416\n",
      "\u001B[1m20/20\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n",
      "animal dog afghan accuracy: 0.08589951377633712\n",
      "\u001B[1m20/20\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n",
      "animal dog african_wild_dog accuracy: 0.083596214511041\n",
      "\u001B[1m21/21\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n",
      "animal dog airedale accuracy: 0.08385093167701864\n",
      "\u001B[1m21/21\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n",
      "animal dog american_bulldog accuracy: 0.08497723823975721\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
